{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aula 9 - Parte 1 - Processamento de Linguagem Natural\n",
    "\n",
    "Esse notebook descreve o passo a passo a ser aplicado para o Processamento de Linguagem Natural para criar uma an√°lise de sentimento em coment√°rios sobre o Youtube."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ti = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Essa biblioteca realiza o tratamento da linguagem natural \n",
    "# com diversas ferramentas dispon√≠veis (NLTK - Natural Language Tookit)\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necess√°rio realizar o download das palavras StopWords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lematizador para palavras em Portugues\n",
    "nltk.download('rslp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Carregar bases de dados\n",
    "\n",
    "A base de dados est√° salvo em formato de CSV. Onde o primeiro elemento √© o texto e o segundo elemento √© a classe.\n",
    "\n",
    " | texto | classe |\n",
    " | --- | --- |\n",
    " |0\t|@pandlrcom Quem √© que liga pra copa gente? Pelo o amor de Deus\t|negativo\n",
    "|1\t|Faz a sele√ß√£o a√≠ do teu time ‚Äî eu e a carol no ataque, Thaynara e veve na zaga, Luise no gol!!! √â esse? kkk\t|neutro\n",
    "|2|\tCristiano Ronaldo com grife, 78 milh√µes de euros üòé\t\t|positivo\n",
    "\n",
    "\n",
    "Iremos estruturar os dados para facilitar todo o processo de cria√ß√£o do algoritmo de an√°lise de sentimento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def carregar_dados(arquivo):\n",
    "    dados = pd.read_csv(arquivo, sep=';', encoding='utf-8')\n",
    "    \n",
    "    base = []\n",
    "    for i in range(len(dados)):\n",
    "        base.append((dados.texto.loc[i], dados.classe.loc[i]))\n",
    "    return base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_treino = carregar_dados('dados_treino.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_treino[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_teste = carregar_dados('dados_teste.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_teste[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tamanho base de treino: \", len(base_treino))\n",
    "print(\"Tamanho base de teste: \", len(base_teste))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(base_treino[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pr√© Processamento\n",
    "\n",
    "Esta primeira etapa tem o prop√≥sito de realizar o pr√©-processamento dos dados, necess√°rio para a prepara√ß√£o da base de dados para algoritmos de aprendizagem de m√°quina.\n",
    "\n",
    "Essa etapa envolve os seguintes passos:\n",
    "\n",
    "    2.1 - Remo√ß√£o de pontua√ß√£o, deixar tudo min√∫sculo e remo√ß√£o de URLs, RT e @user\n",
    "    2.2 - Remo√ß√£o de Stopwords\n",
    "    2.3 - Remo√ß√£o do radical das palavras (Stemming)\n",
    "    2.4 - Listagem de todas as palavras da base\n",
    "    2.5 - Extra√ß√£o de palavras √∫nicas\n",
    "    2.6 - Jun√ß√£o de palavras √∫nicas\n",
    "    2.7 - Extra√ß√£o de palavras de cada frase\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 - Remo√ß√£o de pontua√ß√£o, deixar tudo min√∫sculo e remo√ß√£o de URLs, RT e @user\n",
    "\n",
    "O objetivo dessa etapa √© realizar um tratamento no texto removendo as pontua√ß√µes, urls, RTs, men√ß√£o a usu√°rios e tamb√©m padronizar toda a frase e min√∫scula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tratar_texto(texto):\n",
    "    string_sem_url = re.sub(r\"http\\S+\", \"\", str(texto))\n",
    "    string_sem_user = re.sub(r\"@\\S+\", \"\", str(string_sem_url))\n",
    "    string_sem_rt = re.sub(r\"RT+\", \"\", str(string_sem_user))\n",
    "    return str(string_sem_rt).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tratar_texto('Esse link √© √≥timo http://ashdfasdfa.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tratar_texto('RT @user a copa est√° demais')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tratar_texto('@user a copa est√° demais')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tratar_texto('RT a copa est√° demais')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remover_pontuacao(base):\n",
    "    \"\"\"Essa fun√ß√£o remove as pontua√ß√µes da base.\n",
    "    Args:\n",
    "        base: cont√©m todos tweets no formato (texto,classe).\n",
    "    Returns:\n",
    "        base_dados: √â uma lista de tuplas.\n",
    "    \"\"\"\n",
    "    frases_final = []\n",
    "    for (frase, classe) in base:\n",
    "        sem_pontuacao = []\n",
    "        # Para cada palavra na frase\n",
    "        frase = tratar_texto(frase)\n",
    "        for p in frase:\n",
    "            # Verifica se n√£o √© uma pontua√ß√£o\n",
    "            if p not in string.punctuation:\n",
    "                sem_pontuacao.append(p)\n",
    "        # Refaz a frase\n",
    "        aux = ''.join(sem_pontuacao)\n",
    "        # Salva na lista final no formato (texto,classe)\n",
    "        frases_final.append((aux.lower(), classe))\n",
    "    # Retorna todo o conjunto sem as pontua√ß√µes\n",
    "    return (frases_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(base_treino[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(remover_pontuacao([base_treino[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frases_sem_pontuacao = remover_pontuacao(base_treino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(frases_sem_pontuacao[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 - Remo√ß√£o de Stopwords\n",
    "\n",
    "As stopwords s√£o palavras que n√£o possuem significado para o desempenho dos algoritmos de classifica√ß√£o de texto. Por exemplo: '√©', 'muito', 'o', 'por', entre outros.\n",
    "\n",
    "A perman√™ncia delas na base de dados, pode provocar maior lentid√£o no processamento dos dados, sem utilidade para o contexto em que estamos trabalhando.\n",
    "\n",
    "A fun√ß√£o ```remover_stopwords``` funciona da seguinte forma:\n",
    "\n",
    "- O par√¢metro \"frases_sem_pontuacao\" representa toda a base de dados j√° tratada.\n",
    "- Essa base de dados cont√©m um par de elementos sendo o primeiro a frase e o segundo a classe (positivo, negativo, neutro).\n",
    "- A fun√ß√£o percorre toda a base de dados, linha a linha, verificando em quais frases possuem as stopwords definidas na biblioteca NLTK. Uma vez identificadas, elas s√£o removidas da frase. \n",
    "- O conjunto final √© uma estrutura contendo a frase (sem as stopwords) e a classe (positivo, negativo, neutro)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega as stopwords definidas na biblioteca para o idioma Portugu√™s\n",
    "stopwordsnltk = nltk.corpus.stopwords.words('portuguese')\n",
    "\n",
    "# Adiciona novas stopwords\n",
    "stopwordsnltk.append('vou')\n",
    "stopwordsnltk.append('t√£o')\n",
    "\n",
    "# Visualiza algumas\n",
    "print(stopwordsnltk[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remover_stopwords(frases_sem_pontuacao):\n",
    "    \"\"\"Essa fun√ß√£o remove as stopwords da base.\n",
    "    Args:\n",
    "        frases_sem_pontuacao: √â uma lista de tuplas.\n",
    "    Returns:\n",
    "        frases_final: √â uma lista de tuplas (texto, classe).\n",
    "    \"\"\"\n",
    "    stopwordsnltk = nltk.corpus.stopwords.words('portuguese')\n",
    "    frases_final = []\n",
    "    for (frase, classe) in frases_sem_pontuacao:\n",
    "        sem_stop = []\n",
    "        for palavra in frase.split():\n",
    "            if palavra not in stopwordsnltk:\n",
    "                sem_stop.append(palavra)  \n",
    "        frases_final.append((sem_stop, classe))\n",
    "    return frases_final\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Vari√°vel que armazena o resultado da fun√ß√£o remover_stopwords\n",
    "frases_sem_stopwords = remover_stopwords(frases_sem_pontuacao)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(frases_sem_stopwords[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 - Remo√ß√£o do radical das palavras (Stemming)\n",
    "\n",
    "Stemming √© uma t√©cnica utilizada para reduzir a dimensionalidade dos dados na etapa de pr√©-processamento. √â baseada na redu√ß√£o de palavras em seu morfema, de acordo com as regras do idioma que o algoritmo ser√° executado. \n",
    "\n",
    "Por exemplo, em portugu√™s a palavra ‚Äúcasa‚Äù possui o morfema ‚Äúcas‚Äù e suas varia√ß√µes: casinhas, casebre, casona.\n",
    "\n",
    "A fun√ß√£o ```aplicar_stemmer``` funciona da seguinte forma:\n",
    "\n",
    "- Utiliza-se uma ferramenta da biblioteca NLTK para realizar essa t√©cnica. Para isso, acessamos o pacote ```stem``` para realizar essa tarefa.\n",
    "- ```nltk.stem.RSLPStemmer()``` indica que ser√° utilizado a lingua portguesa.\n",
    "- O par√¢metro ```frases_sem_stopwords``` da fun√ß√£o ```aplicar_stemmer``` representa a base de dados sem as stopwords que foram removidas anteriormente.\n",
    "\n",
    "- A fun√ß√£o percorre toda a base de dados aplicando o m√©todo ```stemmer.stem(palavra)``` em cada palavra de cada frase, cuja finalidade √© deixar apenas o radical de cada palavra.\n",
    "\n",
    "- Exemplo: A frase ```('eu sou admirada por muitos','positivo')```, ap√≥s a fun√ß√£o ```aplicar_stemmer``` ficar√° ```(['admir', 'muit'], 'positivo')```\n",
    "\n",
    "Uma desvantagem da aplica√ß√£o do algoritmo stemmer √© quando duas palavras com sentidos diferentes possuem o mesmo radical, como por exemplo as palavras ```novamente``` e ```novo``` que possuem o radical ```nov``` dessa forma, na etapa de aprendizado de m√°quina o algoritmo pode perder algumas informa√ß√µes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def aplicar_stemmer(frases_sem_stopwords):\n",
    "    \"\"\"Fun√ß√£o que reduz a palavra ao seu radical\n",
    "    Args:\n",
    "        frases_sem_stopwords: lista de tuplas.\n",
    "    Returns:\n",
    "        frases_stemming: lista de tuplas.\n",
    "    \"\"\"\n",
    "    stemmer = nltk.stem.RSLPStemmer()\n",
    "    frases_stemming =[]\n",
    "    for (frase, classe) in frases_sem_stopwords:\n",
    "        com_stemming = []\n",
    "        # Para cada palavra na frase, aplicar o stemmer e salvar\n",
    "        for palavra in frase:\n",
    "            com_stemming.append(str(stemmer.stem(palavra)))\n",
    "        frases_stemming.append((com_stemming, classe))    \n",
    "    # Retornar todo o conjunto com o stemming aplicado\n",
    "    return frases_stemming\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frases_com_stemmer = aplicar_stemmer(frases_sem_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(frases_com_stemmer[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 - Listagem de todas as palavras da base\n",
    "\n",
    "A fun√ß√£o ```extrair_palavras``` ir√° gerar uma nova lista com todas as palavras que j√° foram pr√©-processadas anteriormente por√©m sem a sua classifica√ß√£o (positivo, negativo e neutro) associada.\n",
    "\n",
    "Funciona da seguinte forma:\n",
    "- O par√¢metro da fun√ß√£o representa a lista gerada pela fun√ß√£o aplicar_stemmer, que √© a ```frases_com_stemmer```.\n",
    "- Ela percorre toda a base e insere em uma lista com todas as palavras da base de dados, mas sem sua classifica√ß√£o associada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extrair_palavras(frases_com_stemmer):\n",
    "    \"\"\"Fun√ß√£o que unifica todas as palavras do conjunto de dados em uma √∫nica lista.\n",
    "    Args:\n",
    "        frases_com_stemmer: Frases com o Stemmer j√° aplicados.\n",
    "    Returns:\n",
    "        todas_palavras: lista com todas as palavras.\n",
    "    \"\"\"\n",
    "    todas_palavras = []\n",
    "    for (palavras, classe) in frases_com_stemmer:\n",
    "        todas_palavras.extend(palavras)\n",
    "    return todas_palavras\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "palavras_sem_classe = extrair_palavras(frases_com_stemmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palavras_sem_classe[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 - Extra√ß√£o de palavras √∫nicas\n",
    "\n",
    "Na fun√ß√£o ```aplicar_frequencia``` iremos remover os radicais repitidos da base para otimizar o processamento dos dados utilizando o recurso do nltk ```FreqDist```.\n",
    "\n",
    "A classe ```FreqDist``` unifica todas as palavras repetidas gerando um dicion√°rio do tipo ```chave,valor``` dentro de uma lista, sendo a chave o radical e o valor a frequencia com que ele se repete. Ex: ```('am', 4)```. Nesse exemplo o radical ```am``` apareceu na base de dados 4 vezes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def aplicar_frequencia(palavras_sem_classe):\n",
    "    \"\"\"Fun√ß√£o que aplica a frequencia das palavras\n",
    "    Args:\n",
    "        palavras_sem_classe: palvras sem a classifica√ß√£o.\n",
    "    Returns:\n",
    "        palavras: FreqDist\n",
    "    \"\"\"\n",
    "    palavras = nltk.FreqDist(palavras_sem_classe)\n",
    "    return palavras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frequencia_palavras = aplicar_frequencia(palavras_sem_classe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencia_palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar as 50 frases mais completas\n",
    "print(frequencia_palavras.most_common(50))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 - Jun√ß√£o de palavras √∫nicas\n",
    "\n",
    "Al√©m disso, temos que criar uma estrutura apenas com as palavras √∫nicas da frequ√™ncia gerada anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extrair_palavras_unicas(frequencia_palavras):\n",
    "    \"\"\"Fun√ß√£o que retorna as palavras √∫nicas\n",
    "    Args:\n",
    "        frequencia_palavras: dicion√°rio com a frequencia das palavras.\n",
    "    Returns:\n",
    "        freq: palavras unicas.\n",
    "    \"\"\"\n",
    "    freq = frequencia_palavras.keys()\n",
    "    return freq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "palavras_sem_repeticao = extrair_palavras_unicas(frequencia_palavras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para visualizar as 5 primeiras palavras √© necess√°rio realizar uma convers√£o direta para o tipo lista\n",
    "print(list(palavras_sem_repeticao)[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A estrutura criada √© do tipo dict_keys, que representam as chaves de um dicion√°rio\n",
    "print(type(palavras_sem_repeticao))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 - Extra√ß√£o de palavras de cada frase\n",
    "\n",
    "O objetivo da fun√ß√£o ```criar_caracteristicas``` √© auxiliar a caracteriza√ß√£o das frases a serem utilizadas no algoritmo Naive Bayes.\n",
    "\n",
    "O m√©todo ```nltk.classify.apply_features``` realiza essa caracteriza√ß√£o atrav√©s do mapeamento de cada frase na fun√ß√£o ```criar_caracteristicas```. O resultado desse mapeamento √© um dicion√°rio para cada frase onde as palavras que pertencem a respectiva frase sejam ```True```. Todas as outras palavras da base que n√£o pertencem a frase ser√£o definidas como ```False```.\n",
    "\n",
    "O m√©todo ```nltk.classify.apply_features``` exige dois par√¢metros, sendo o primeiro uma fun√ß√£o que ir√° extrair as caracteristicas e o segundo √© o conjunto de dados onde ser√° aplicado essa caracteriza√ß√£o.\n",
    "\n",
    "Essa etapa √© necess√°ria para a prepara√ß√£o da base de dados para o algoritmo de aprendizagem de m√°quina Naive Bayes. √â o resultado dessa fun√ß√£o que ir√° ser passada como par√¢metro para criar o classificador.\n",
    "\n",
    "A fun√ß√£o ```criar_caracteristicas``` recebe a lista com as palavras com o stemming e cria uma estrutura onde apenas as palavras que est√£o nessa lista ser√° marcada como ```True```, todas as outras ser√£o marcadas como ```False```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def criar_caracteristicas(documento):\n",
    "    \"\"\"Fun√ß√£o que cria as caracter√≠sticas do documento, verificando se a palavra existe ou n√£o no documento.\n",
    "    Args:\n",
    "        documento: lista com todas as palavras\n",
    "    Returns:\n",
    "        caracteristicas: dicion√°rio com as caracter√≠sticas.\n",
    "    \"\"\"\n",
    "    global palavras_sem_repeticao\n",
    "    doc = set(documento)\n",
    "    caracteristicas = {}\n",
    "    # Para cada palavra\n",
    "    for palavra in palavras_sem_repeticao:\n",
    "        # Se a palavra existir no documento √© atribuido True, caso contr√°rio False.\n",
    "        caracteristicas[palavra] = (palavra in doc)    \n",
    "    # Listar com as caracteristicas da palavra\n",
    "    return caracteristicas\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O c√≥digo abaixo √© apenas para testar e validar a fun√ß√£o ```criar_caracteristicas```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Para testar a fun√ß√£o acima, ser√° utilizado duas frases que j√° foi aplicado o stemmer.\n",
    "teste_caracteristica = frases_com_stemmer[0:2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(teste_caracteristica)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(extrair_palavras(teste_caracteristica))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A execu√ß√£o ```nltk.classify.apply_features``` ir√° gerar uma lista, onde cada elemento dessa lista √© uma tupla com dois elementos, sendo o primeiro o dicion√°rio gerado pela fun√ß√£o ```criar_caracteristicas``` e o segundo elemento com a classifica√ß√£o (positivo, negativo, neutro)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frases_teste_final = nltk.classify.apply_features(criar_caracteristicas, teste_caracteristica)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar 1 elemento classificado\n",
    "print(frases_teste_final[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para facilitar a reutiliza√ß√£o de todo o c√≥digo criado anteriormente, iremos criar uma fun√ß√£o para estruturar qualquer texto que desejamos classificar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def estruturar_dados(base):\n",
    "    \"\"\"Dada uma base de dados, √© realizada toda a estrutura√ß√£o das bases.\n",
    "    Args:\n",
    "        base: cont√©m todos tweets no formato (texto,classe).\n",
    "    Returns:\n",
    "        base_final: conjunto de dados estruturados.\n",
    "    \"\"\"\n",
    "    global palavras_sem_repeticao\n",
    "    # Aplicar as fun√ß√µes previamente definidas\n",
    "    frases_sem_pontuacao = remover_pontuacao(base)\n",
    "    frases_sem_stopwords = remover_stopwords(frases_sem_pontuacao)\n",
    "    frases_com_stemmer = aplicar_stemmer(frases_sem_stopwords)\n",
    "    palavras_sem_classe = extrair_palavras(frases_com_stemmer)\n",
    "    frequencia_palavras = aplicar_frequencia(palavras_sem_classe)\n",
    "    palavras_sem_repeticao = extrair_palavras_unicas(frequencia_palavras)\n",
    "    base_final = nltk.classify.apply_features(criar_caracteristicas, frases_com_stemmer)\n",
    "    # Retornar os dados estruturados para serem utilizados pela fun√ß√£o NLTK.\n",
    "    return (base_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fase de treino do algoritmo Naive Bayes\n",
    "\n",
    "Nesta etapa ser√° realizado o treino do algoritmo Naive Bayes, que ir√° gerar um modelo a ser utilizado na classifica√ß√£o de novas frases em positivo, negativo ou neutro.\n",
    "\n",
    "## 3.1 Classifica√ß√£o do texto\n",
    "\n",
    "O algoritmo de Naive Bayes realiza a an√°lise estat√≠stica e monta uma tabela de probabilidade. Ap√≥s isso, √© criada a classifica√ß√£o dos registros.\n",
    "\n",
    "O m√©todo ```train``` da classe ```NaiveBayesClassifier``` recebe como par√¢metro a ```base_treino``` j√° estruturada (```base_final```) e realiza a etapa de constru√ß√£o da tabela de probabilidades. O m√©todo ```show_most_informative_features``` retorna os atributos (palavras) mais significativos.\n",
    "\n",
    "Por exemplo: \n",
    "\n",
    "- ```dia = True positi : negati = 2.3:1.0``` - Neste exemplo de sa√≠da a probabilidade de a frase ser classificada como ```positivo``` quando a palavra \"dia\" estiver presente na frase (```True```) √© 2.3 vezes maior do que negativo.\n",
    "\n",
    "- ```am = False negati : positi = 1.6:1.0``` - J√° neste exemplo, a probabilidade de a frase ser classificada como ```negativo``` quando a palavra ```am``` **n√£o** estiver presente na frase (```False```) √© 1.6 vezes maior do que positivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_final = estruturar_dados(base_treino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Cria o classificador (tabela de probabilidade) com base no conjunto de treinamento\n",
    "classificador = nltk.NaiveBayesClassifier.train(base_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retorna as classes da base de dados (positivo, negativo, neutro)\n",
    "print(classificador.labels())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retorna os 10 atributos mais significativos\n",
    "print(classificador.show_most_informative_features(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Testando o classificador\n",
    "\n",
    "Para testar o classificador, iremos utilizar uma frase para verificar a classifica√ß√£o realizada, uma vez que a base de dados j√° foi pr√©-processada e treinada com a base de dados para treino.\n",
    "\n",
    "Para que a nova frase seja classificada temos que realizar toda a fase de pr√©-processamento. Como criamos a fun√ß√£o ```estruturar_dados``` podemos simplesmente utiliz√°-la :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_teste[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frase_teste = estruturar_dados([base_teste[0]])\n",
    "print(frase_teste)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(frase_teste[0][0])\n",
    "caracteristica_teste = frase_teste[0][0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quando chamamos o m√©todo ```classificador.classify``` com o par√¢metro ```frase_teste```, o algoritmo classifica a frase como r√≥tulo ```negativo```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizar a classifica√ß√£o\n",
    "print(classificador.classify(caracteristica_teste))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para visualizar a distribui√ß√£o de probabilidade utiliza-se o m√©todo ```prob_classify``` que mostra a porcentagem para cada uma das classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retorna a classe e o valor da distribui√ß√£o de probabilidade\n",
    "distribuicao = classificador.prob_classify(caracteristica_teste)\n",
    "\n",
    "# Para cada classe, verifica-se a probabilidade\n",
    "for classe in distribuicao.samples():\n",
    "    print('%s: %f' % (classe, distribuicao.prob(classe)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Fase de teste do algoritmo Naive Bayes\n",
    "\n",
    "Na etapa de teste, utiliza-se outro conjunto de dados, com o objetivo de testar o algoritmo de aprendizado de m√°quina com novas frases. Para tal, a base de dados deve conter frases diferentes da base de treinamento e sem a informa√ß√£o de sua classifica√ß√£o (positivo, negativo e neutro).\n",
    "\n",
    "O algoritmo √© executado novamente e o m√©todo ```classify.accuracy```  mostra a proximidade entre o percentual obtido experimentalmente e o valor verdadeiro da classifica√ß√£o das frases.\n",
    "\n",
    "Passamos como par√¢metro o classificador, que nada mais √© do que uma tabela de probabilidade que o Naive Bayes gera, e a base de dados para teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frases_teste = estruturar_dados(base_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(frases_teste[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O m√©todo ```classify.accuracy``` funciona da seguinte forma: ele submete todos os registros da base de teste ao classificador e o classificador gera uma classifica√ß√£o para cada um dos registros. Ap√≥s isso, realiza uma compara√ß√£o entre a classifica√ß√£o gerada e a classifca√ß√£o que j√° tinha sido realizada na base de dados, e devolve a taxa de acerto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nltk.classify.accuracy(classificador, frases_teste))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esse resultado, possibilita realizar algumas an√°lises, tais como:\n",
    "\n",
    "1. **An√°lise de cen√°ro**: O percentual de acerto do algoritmo √© bom ou ruim? \n",
    "2. **An√°lise do numero de classes**: A probabilidade m√≠nima aceitavel para o algoritmo ser melhor do que usar a aleatoriedade √© que a acur√°cia seja no m√≠nimo maior que 33.33%, ou seja, dividir 100% pela quantidade de classes.\n",
    "3. **ZeroRules**: Nessa an√°lise, estamos comparando o resultado obtido pelo sistema, com o m√©todo de classificar uma frase de acordo com a classe que possui maior quantidade de frases na base de dados de treino e teste. Por exemplo, dividimos a classe com maior n√∫mero de registros pelo total de registros na base de dados (```459/1374 = 33,40%```). Desta forma, conclui-se que o sistema apresenta mais acertos do que classificar todas as novas frases nessa classe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = {'positivo' : 0, 'negativo' : 0, 'neutro' : 0}\n",
    "total = 0\n",
    "for (texto, classe) in base_teste:\n",
    "    if classe == 'positivo':\n",
    "        res[classe] += 1\n",
    "    elif classe == 'negativo':\n",
    "        res[classe] += 1\n",
    "    elif classe == 'neutro':\n",
    "        res[classe] += 1\n",
    "    total += 1\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(res['negativo']/total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Extra - Visualiza√ß√£o de erros do algoritmo\n",
    "\n",
    "√â poss√≠vel visualizar a classe j√° pr√©-classificada, a classe que o algoritmo classificou e a frase vinculada ao erro gerado.\n",
    "\n",
    "Por exemplo: ```positivo negativo {'trabalh': False, ... , 'precis': True,'ingress': True, 'estrag': False,...}```. Essa sa√≠da nos diz qual a classe correta, ou seja, aquela que est√° na base de dados para teste √© ```positivo```. O algoritmo classificou como ```negativo``` e a frase vinculada a classifica√ß√£o possui os radicais ```precis``` e ```ingress```.\n",
    "\n",
    "Para identificar corretamente os acertos e erros podemos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "erros =[]\n",
    "for (frase, classe) in frases_teste:\n",
    "    resultado = classificador.classify(frase)\n",
    "    \n",
    "    if resultado != classe:\n",
    "        erros.append((classe, resultado, frase))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desta forma, √© poss√≠vel verificar a porcentagem de erro e acerto realizado no conjunto de dados de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tamanho_base_teste = len(frases_teste)\n",
    "quantida_erros = len(erros)\n",
    "\n",
    "porcentagem_erros = (quantida_erros * 100) / tamanho_base_teste\n",
    "porcentagem_acertos = 100 - porcentagem_erros\n",
    "\n",
    "print(\"O algoritmo classificou {:.4}% das frases corretamente\".format(porcentagem_erros))\n",
    "print(\"O algoritmo classificou {:.4}% das frases incorretamente\".format(porcentagem_acertos))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Matriz de confus√£o\n",
    "\n",
    "Outra forma de visualiza√ß√£o de erros e acertos, √© a constru√ß√£o da matriz de confus√£o:\n",
    "\n",
    "- Primeiramente importamos o pacote do ```nltk``` com a fun√ß√£o da matriz de confus√£o.\n",
    "- Criamos duas listas, uma com o resultado ```esperado``` e outra com o resultado ```previsto```, sendo que o esperado √© o resultado desejado como resposta, e o previsto √© de fato a classifica√ß√£o realizada.\n",
    "- A sa√≠da do algoritmo mostra uma matriz com linhas que represantam o esperado e colunas que representam o previsto.\n",
    "- A diagonal principal indica a quantidade de acertos de cada classe.\n",
    "\n",
    "Esses resultados apresentam as classes que o algoritmo est√° mais errando e/ou acertando, sendo assim, √© poss√≠vel tomar decis√µes para melhorar a implementa√ß√£o da base de dados, bem como alguns par√¢metros de otimiza√ß√£o do algoritmo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.metrics import ConfusionMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "esperado = []\n",
    "previsto = []\n",
    "for (frase, classe) in frases_teste:\n",
    "    resultado = classificador.classify(frase)\n",
    "    previsto.append(resultado)\n",
    "    esperado.append(classe)\n",
    "\n",
    "matriz = ConfusionMatrix(esperado, previsto)\n",
    "print(matriz)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Utilizaremos ambos os conjuntos de dados para criar o modelo final\n",
    "\n",
    "Uma vez verificado a acuracia e as m√©tricas em nosso conjunto de dados de treino e teste, podemos unificar esses dois conjuntos de dados para utilizar todas as palavras com o objetivo de maximar a curva de aprendizado do algoritmo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(base_teste), type(base_treino))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conj_final = estruturar_dados(base_teste+base_treino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Cria o classificador (tabela de probabilidade) com base no conjunto de treinamento\n",
    "classificador_final = nltk.NaiveBayesClassifier.train(conj_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retorna as classes da base de dados (positivo, negativo, neutro)\n",
    "print(classificador_final.labels())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retorna os 10 atributos mais significativos\n",
    "print(classificador_final.show_most_informative_features(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Salvar o modelo criado para realizar a an√°lise de sentimento nos videos do Youtube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def salvar_modelo(modelo, nome_arquivo):\n",
    "    nome = str(nome_arquivo) + \".pickle\"\n",
    "    try:\n",
    "        salvar_modelo = open(nome,\"wb\")\n",
    "        pickle.dump(modelo, salvar_modelo)\n",
    "        salvar_modelo.close()\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if salvar_modelo(classificador,'naivebayes'):\n",
    "    print(\"Modelo salvo para ser utilizado no futuro :)\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tempo total para executar esse notebook foi de {} segundos\".format(time() - ti))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
